{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bb38baf3",
   "metadata": {},
   "source": [
    "# Cas-Detector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea13018b",
   "metadata": {},
   "source": [
    "## 1. Pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1f8901b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import torch.optim as optim\n",
    "import os\n",
    "import re\n",
    "import math\n",
    "import random\n",
    "import time\n",
    "from datetime import datetime\n",
    "import copy\n",
    "import glob\n",
    "import gc\n",
    "import pickle\n",
    "import h5py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdd4b55f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 预定义的变量\n",
    "project_path = '/home/fengchr/staff/Cas-detector'\n",
    "\n",
    "# 设定随机数种子\n",
    "torch.manual_seed(201)\n",
    "torch.cuda.manual_seed(88)\n",
    "\n",
    "# 模型超参数\n",
    "noncas_weight = 0.25 #nonCas对Cas样本的权重比\n",
    "window_size = 64  # 片段长度\n",
    "window_step = 25\n",
    "lr = 0.015\n",
    "momentum = 0.8\n",
    "batch_size = 256\n",
    "lr_fixed_decay = 0.9\n",
    "lr_fixed_decay_every = 2500\n",
    "inspect_loss_decay = 0.75  # 每当loss下降为原来的inspect_loss_decay，便更新一次lr\n",
    "lr_adapt_decay = 0.75  # 更新lr为原来的lr_adapt_decay\n",
    "inspect_num = 5  # 以inspect_num个batch为单位判定模型收敛程度\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89a72b29",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tools\n",
    "def read_fasta(input):\n",
    "    with open(input,'r') as f:\n",
    "        fasta = {}\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if line[0] == '>':\n",
    "                header = line[1:]\n",
    "            else:\n",
    "                sequence = line\n",
    "                fasta[header] = fasta.get(header,'') + sequence\n",
    "        return fasta\n",
    "def split_seq(seq,window_size,step=window_step):#具体step为多少需要外部判断\n",
    "    if len(seq) < window_size:\n",
    "        return([])\n",
    "    out=[seq[i:i+window_size] for i in range(random.randint(0,step-1),len(seq)-window_size+1,step)]\n",
    "    return(out)\n",
    "def split_seq_rand(seq,window_size,num):#具体num为多少需要外部判断\n",
    "    if len(seq) < window_size:\n",
    "        return([])\n",
    "    out=[]\n",
    "    for i in range(num):\n",
    "        tmp=random.randint(0,len(seq)-window_size)\n",
    "        out.append(seq[tmp:tmp+window_size])\n",
    "    return(out)\n",
    "def one_hot_encode(lst):\n",
    "    encode_dict = {}\n",
    "    for i in range(len(lst)):\n",
    "        tmp=np.zeros(len(lst))\n",
    "        tmp[i]=1\n",
    "        encode_dict[lst[i]]=tmp\n",
    "    return encode_dict\n",
    "encode_dict=one_hot_encode([\"A\",\"R\",\"N\",\"D\",\"C\",\"Q\",\"E\",\"G\",\"H\",\"I\",\"L\",\"K\",\"M\",\"F\",\"P\",\"S\",\"T\",\"W\",\"Y\",\"V\",\"-\"])\n",
    "print(\"encode_dict:\")\n",
    "print(encode_dict)\n",
    "def encode_aa_lst(aa_lst):\n",
    "    return([torch.tensor(np.array([encode_dict.get(j,encode_dict[\"-\"]) for j in list(aa)]), dtype=torch.float32) for aa in aa_lst])\n",
    "\n",
    "def save_model(run_header, epoch, model):\n",
    "    state = {\n",
    "        'state_dict': model.state_dict()\n",
    "    }\n",
    "    torch.save(state, project_path + \"/\"+run_header+\".epoch_\"+str(epoch)+\".model.pkl\")\n",
    "def load_model(run_header, epoch):\n",
    "    state = torch.load(project_path + \"/\"+run_header+\".epoch_\"+str(epoch)+\".model.pkl\")\n",
    "    tmp = MyModel()\n",
    "    tmp.to(device)\n",
    "    tmp.load_state_dict(state['state_dict'])\n",
    "    tmp.eval()\n",
    "    return(tmp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ed912c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import T5Tokenizer, T5EncoderModel\n",
    "\n",
    "device = torch.device('cuda:0')\n",
    "\n",
    "# Load the tokenizer\n",
    "tokenizer = T5Tokenizer.from_pretrained(project_path + '/embedding/prot_t5_xl_half_uniref50-enc', do_lower_case=False)\n",
    "\n",
    "# Load the model\n",
    "model = T5EncoderModel.from_pretrained(project_path + '/embedding/prot_t5_xl_half_uniref50-enc').to(device)\n",
    "\n",
    "# only GPUs support half-precision currently; if you want to run on CPU use full-precision (not recommended, much slower)\n",
    "model.half()\n",
    "model = model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06ab2c08",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(project_path + '/data/target_encode_dict.pkl', 'rb') as file:\n",
    "    target_encode_dict = pickle.load(file)\n",
    "\n",
    "all_type_num = len(target_encode_dict)\n",
    "cas_types = list(target_encode_dict.keys())[-1]\n",
    "weight = torch.tensor([1]*(all_type_num - 1)+[noncas_weight])\n",
    "print(target_encode_dict)\n",
    "print(\"All types num: \" + str(all_type_num))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e89acfd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "with h5py.File(project_path + '/data/data_cas_12_26.h5', 'r') as f:\n",
    "    cas_emb = np.array(f['cas_emb'])\n",
    "    cas_labels = np.array(f['cas_labels'])\n",
    "with h5py.File(project_path + '/data/data_noncas.1.h5', 'r') as f:\n",
    "    noncas_emb = np.array(f['noncas_emb'])\n",
    "    noncas_labels = np.array(f['noncas_labels'])\n",
    "cas_set1 = [(cas_emb[i],cas_labels[i]) for i in range(len(cas_labels))]\n",
    "noncas_set1 = [(noncas_emb[i],noncas_labels[i]) for i in range(len(noncas_labels))]\n",
    "random.shuffle(cas_set1)\n",
    "random.shuffle(noncas_set1)\n",
    "del cas_emb,cas_labels,noncas_emb,noncas_labels\n",
    "\n",
    "print(str(len(cas_set1)))\n",
    "print(str(len(noncas_set1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f00c2978",
   "metadata": {},
   "outputs": [],
   "source": [
    "#定义数据加载类\n",
    "class MyDataset(Dataset):\n",
    "    def __init__(self, dataset, k, state='train'):#k:十折交叉验证index\n",
    "        overall_size = len(dataset)\n",
    "        if state == 'train':\n",
    "            index2 = list(range(int((k % 10) * overall_size / 10))) + \\\n",
    "                     list(range(int((k % 10 + 1) * overall_size / 10), overall_size))\n",
    "            self.inputset = [dataset[k][0] for k in index2]\n",
    "            self.targetset = [dataset[k][1] for k in index2]\n",
    "        if state == 'test':\n",
    "            index2 = list(range(int((k % 10) * overall_size / 10), int((k % 10 + 1) * overall_size / 10)))\n",
    "            self.inputset = [dataset[k][0] for k in index2]\n",
    "            self.targetset = [dataset[k][1] for k in index2]\n",
    "        if state == 'all':\n",
    "            self.inputset = [k[0] for k in dataset]\n",
    "            self.targetset = [k[1] for k in dataset]\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        input = self.inputset[idx]\n",
    "        label = self.targetset[idx]\n",
    "        return input, label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.targetset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c86ce6a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#定义模型\n",
    "class MyModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.pool = nn.MaxPool2d(2)\n",
    "        self.conv1 = nn.Conv2d(1, 128, (11,31), stride=(1,3), padding=(5,5))\n",
    "        self.conv2 = nn.Conv2d(128, 128, (11,31), stride=(1,3), padding=(5,5))\n",
    "        self.conv3 = nn.Conv2d(128, 64, (7,13), stride=(1,1), padding=(3,6))\n",
    "        self.conv4 = nn.Conv2d(64, 64, (5,7), stride=(1,1), padding=(2,3))\n",
    "        self.fc1 = nn.Linear(64 * 16 * 24, 256)\n",
    "        self.fc2 = nn.Linear(256, 64)\n",
    "        self.fc3 = nn.Linear(64, all_type_num)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x))) #[batch_size,128,32,167]\n",
    "        x = self.pool(F.relu(self.conv2(x))) #[batch_size,128,16,24]\n",
    "        x = F.relu(self.conv3(x)) #[batch_size,64,16,24]\n",
    "        x = F.relu(self.conv4(x)) #[batch_size,64,16,24]\n",
    "        x = torch.flatten(x, 1) # flatten all dimensions except batch\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.sigmoid(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8e4108d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#定义训练方法\n",
    "cuda_avail = torch.cuda.is_available()\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "print(cuda_avail)\n",
    "\n",
    "#writer\n",
    "current_time = datetime.now()\n",
    "formatted_time = current_time.strftime(\"%m-%d-%H-%M-%S\")\n",
    "run_header=formatted_time\n",
    "writer = SummaryWriter(project_path + \"/model/\" + run_header)\n",
    "j = 0\n",
    "writer_title=formatted_time+\" fold=\"+str(j)\n",
    "\n",
    "#training data\n",
    "my_cas_data = MyDataset(dataset=cas_set1, k=j, state='train')\n",
    "my_cas_loader = torch.utils.data.DataLoader(my_cas_data, batch_size=int(batch_size/4), shuffle=True, num_workers=0, drop_last=True)\n",
    "my_noncas_data = MyDataset(dataset=noncas_set1, k=j, state='train')\n",
    "my_noncas_loader = torch.utils.data.DataLoader(my_noncas_data, batch_size=int(3*batch_size/4), shuffle=True, num_workers=0, drop_last=True)\n",
    "\n",
    "#validation data\n",
    "val_batch_num = 128*4\n",
    "my_val_cas_data = MyDataset(dataset=cas_set1, k=j, state='test')\n",
    "my_val_cas_loader = torch.utils.data.DataLoader(my_val_cas_data, batch_size=int(len(my_val_cas_data)/val_batch_num), shuffle=False, num_workers=0, drop_last=True)\n",
    "# tmp=enumerate(my_val_cas_loader, 0)\n",
    "# _, val_cas_batch=next(tmp)\n",
    "# val_cas_inputs, val_cas_labels = val_cas_batch\n",
    "# val_cas_inputs = val_cas_inputs.unsqueeze(1).to(device)\n",
    "# val_cas_labels = val_cas_labels.to(device)\n",
    "\n",
    "my_val_noncas_data = MyDataset(dataset=noncas_set1, k=j, state='test')\n",
    "my_val_noncas_loader = torch.utils.data.DataLoader(my_val_noncas_data, batch_size=int(len(my_val_noncas_data)/val_batch_num), shuffle=False, num_workers=0, drop_last=True)\n",
    "# tmp=enumerate(my_val_noncas_loader, 0)\n",
    "# _, val_noncas_batch=next(tmp)\n",
    "# val_noncas_inputs, val_noncas_labels = val_noncas_batch\n",
    "# val_noncas_inputs = val_noncas_inputs.unsqueeze(1).to(device)\n",
    "# val_noncas_labels = val_noncas_labels.to(device)\n",
    "\n",
    "#model\n",
    "my_model = MyModel()\n",
    "my_model.to(device)\n",
    "\n",
    "#criterion\n",
    "weight = weight.to(device)\n",
    "criterion = nn.CrossEntropyLoss(weight = weight)\n",
    "\n",
    "#optimizer\n",
    "optimizer = optim.SGD(my_model.parameters(), lr=lr, momentum=momentum)\n",
    "\n",
    "epoch_num = 1\n",
    "write_every = 1\n",
    "test_every = 2500\n",
    "running_loss = []\n",
    "val_loss=[]\n",
    "val_accuracy=[]\n",
    "epoch = -1\n",
    "inspect = False\n",
    "initialize = True\n",
    "converge_level = 0\n",
    "inspect_loss = 0\n",
    "jj = -1\n",
    "noncas_enum = enumerate(my_noncas_loader, 0)\n",
    "def generate_numbers(n):\n",
    "    num = 2\n",
    "    while True:\n",
    "        yield num\n",
    "        num = num % n + 1\n",
    "noncas_generater=generate_numbers(15)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34b6b091",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 人控训练\n",
    "for ss in range(epoch_num):\n",
    "    epoch += 1\n",
    "    my_model.train()\n",
    "    for ii, batch_cas in enumerate(my_cas_loader, 0):\n",
    "        jj+=1\n",
    "        #加载noncas batch\n",
    "        tmp, batch_noncas = next(noncas_enum , (None, None))\n",
    "        if tmp is None:\n",
    "            #加载下一个noncas数据集\n",
    "            noncas_iter = next(noncas_generater)\n",
    "            del noncas_set1, my_noncas_data, my_noncas_loader\n",
    "            gc.collect()\n",
    "            print(\"Loading noncas data \"+str(noncas_iter)+\"...\")\n",
    "            with h5py.File(project_path + '/data/data_noncas.'+str(noncas_iter)+'.h5', 'r') as f:\n",
    "                noncas_emb = np.array(f['noncas_emb'])\n",
    "                noncas_labels = np.array(f['noncas_labels'])\n",
    "            noncas_set1 = [(noncas_emb[i],noncas_labels[i]) for i in range(len(noncas_labels))]\n",
    "            random.shuffle(noncas_set1)\n",
    "            del noncas_emb,noncas_labels\n",
    "            my_noncas_data = MyDataset(dataset=noncas_set1, k=j, state='train')\n",
    "            my_noncas_loader = torch.utils.data.DataLoader(my_noncas_data, batch_size=int(3*batch_size/4), shuffle=True, num_workers=0, drop_last=True)\n",
    "            noncas_enum = enumerate(my_noncas_loader, 0)\n",
    "            tmp, batch_noncas = next(noncas_enum , (None, None))\n",
    "        inputs_cas, labels_cas = batch_cas\n",
    "        inputs_noncas, labels_noncas = batch_noncas\n",
    "        inputs = torch.cat((inputs_cas, inputs_noncas), dim=0)\n",
    "        inputs = inputs.unsqueeze(1).to(device,dtype=torch.float32)\n",
    "        labels = torch.cat((labels_cas, labels_noncas), dim=0)\n",
    "        labels = labels.to(device)\n",
    "        #训练步骤\n",
    "        optimizer.zero_grad()\n",
    "        outputs = my_model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        #记录训练loss\n",
    "        running_loss.append(loss.item())\n",
    "\n",
    "        if initialize and epoch == 0 and ii == 3 * inspect_num + 10:\n",
    "            inspect_loss = sum(running_loss[-inspect_num:]) / inspect_num\n",
    "            inspect = True\n",
    "            initialize = False\n",
    "            print(\"inspect loss initialized as: \" + str(inspect_loss))\n",
    "            print(\"first inspect loss cutoff: \" + str(inspect_loss_decay * inspect_loss))\n",
    "\n",
    "        if jj % write_every == write_every - 1:\n",
    "            writer.add_scalars(writer_title, {'loss': sum(running_loss[-write_every:]) / write_every,\n",
    "                                               '100*lr': optimizer.param_groups[0]['lr'] * 100}, jj)\n",
    "            print(\"[%s]-[%d]-[%d] lr=[%r] loss=[%.3f]\" % (\n",
    "            j, epoch + 1, ii + 1, optimizer.param_groups[0]['lr'], sum(running_loss[-write_every:]) / write_every))\n",
    "        \n",
    "        # loss每降低一半，相应lr也调整为原来的一半\n",
    "        if inspect:\n",
    "            if sum(running_loss[-inspect_num:]) / inspect_num < inspect_loss_decay * inspect_loss:\n",
    "                lr_0 = lr\n",
    "                lr *= lr_adapt_decay\n",
    "                for param_group in optimizer.param_groups:\n",
    "                    param_group[\"lr\"] = lr\n",
    "                inspect_loss *= inspect_loss_decay\n",
    "                converge_level += 1\n",
    "                print(\"lr adapted to \" + str(lr_adapt_decay) + \"*\" + str(lr_0) + \"=\" + str(lr))\n",
    "                print(\"new inspect loss cutoff: \" + str(inspect_loss_decay * inspect_loss))\n",
    "        if jj % test_every == test_every - 1:\n",
    "            my_model.eval()\n",
    "            with torch.no_grad():\n",
    "                epoch_cas_accuracy=[]\n",
    "                epoch_noncas_accuracy=[]\n",
    "                epoch_val_cas_losses=[]\n",
    "                epoch_val_noncas_losses=[]\n",
    "                tmp1 = enumerate(my_val_cas_loader)\n",
    "                tmp2 = enumerate(my_val_noncas_loader)\n",
    "                for t in range(val_batch_num):\n",
    "                    _, val_cas_batch = next(tmp1)\n",
    "                    _, val_noncas_batch = next(tmp2)\n",
    "\n",
    "                    val_cas_inputs, val_cas_labels = val_cas_batch\n",
    "                    val_cas_inputs = val_cas_inputs.unsqueeze(1).to(device,dtype=torch.float32)\n",
    "                    val_cas_labels = val_cas_labels.to(device)\n",
    "                    val_cas_outputs = my_model(val_cas_inputs)\n",
    "                    loss_cas = criterion(val_cas_outputs, val_cas_labels)\n",
    "                    val_cas_max_indices = torch.argmax(val_cas_outputs, dim=1)\n",
    "                    val_cas_acc = torch.sum(val_cas_max_indices == val_cas_labels).item()/val_cas_labels.size()[0]\n",
    "\n",
    "                    val_noncas_inputs, val_noncas_labels = val_noncas_batch\n",
    "                    val_noncas_inputs = val_noncas_inputs.unsqueeze(1).to(device,dtype=torch.float32)\n",
    "                    val_noncas_labels = val_noncas_labels.to(device)\n",
    "                    val_noncas_outputs = my_model(val_noncas_inputs)\n",
    "                    loss_noncas = criterion(val_noncas_outputs, val_noncas_labels)\n",
    "                    val_noncas_max_indices = torch.argmax(val_noncas_outputs, dim=1)\n",
    "                    val_noncas_acc = torch.sum(val_noncas_max_indices == val_noncas_labels).item()/val_noncas_labels.size()[0]\n",
    "\n",
    "                    epoch_val_cas_losses.append(loss_cas.item())\n",
    "                    epoch_val_noncas_losses.append(loss_noncas.item())\n",
    "                    epoch_cas_accuracy.append(val_cas_acc)\n",
    "                    epoch_noncas_accuracy.append(val_noncas_acc)\n",
    "                val_loss.append((sum(epoch_val_cas_losses)/val_batch_num,sum(epoch_val_noncas_losses)/val_batch_num))\n",
    "                val_accuracy.append((sum(epoch_cas_accuracy)/val_batch_num,sum(epoch_noncas_accuracy)/val_batch_num))\n",
    "            writer.add_scalars(writer_title,{'val_cas_loss': val_loss[-1][0],'val_noncas_loss': val_loss[-1][1],'val_average_loss': (val_loss[-1][0]+val_loss[-1][1])/2,'val_cas_accuracy': val_accuracy[-1][0],'val_noncas_accuracy': val_accuracy[-1][1],'val_average_accuracy': (val_accuracy[-1][0]+val_accuracy[-1][1])/2},jj)\n",
    "            print(writer_title)\n",
    "            print('val_cas_loss:',str(val_loss[-1][0]))\n",
    "            print('val_noncas_loss:',str(val_loss[-1][1]))\n",
    "            print('val_cas_accuracy:',str(val_accuracy[-1][0]))\n",
    "            print('val_noncas_accuracy:',str(val_accuracy[-1][1]))\n",
    "        if jj % lr_fixed_decay_every == lr_fixed_decay_every - 1:\n",
    "            lr *= lr_fixed_decay\n",
    "            for param_group in optimizer.param_groups:\n",
    "                param_group[\"lr\"] = lr\n",
    "    # 每个epoch保存一次model：\n",
    "    save_model(run_header=run_header, epoch=epoch, model=my_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57079fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#加载模型\n",
    "import importlib\n",
    "from model_12_27_10_28_52 import MyModel\n",
    "\n",
    "my_model = load_model('12-27-10-28-52',2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d165c6ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objects as go\n",
    "import plotly.io as pio\n",
    "from collections import Counter\n",
    "def split_seq_fixed(seq,window_size,step=window_step):\n",
    "    if len(seq) < window_size:\n",
    "        return([])\n",
    "    out=[seq[i:i+window_size] for i in range(0,len(seq)-window_size+1,step)]\n",
    "    return(out)\n",
    "def predict_seq(mymodel, seq, step=16, title='sequence'):\n",
    "    mymodel.eval()\n",
    "    with torch.no_grad():\n",
    "        seq = seq.replace(\"\\n\",\"\")\n",
    "        split_lst = split_seq_fixed(seq,window_size,step=step)\n",
    "        if len(split_lst) == 0:\n",
    "            print(\"\\\"\"+title+\"\\\" is too short!\")\n",
    "            return\n",
    "        seqs_batch = [\" \".join(list(re.sub(r\"[UZOB]\", \"X\", seq))) for seq in split_lst]\n",
    "        ids = tokenizer(seqs_batch, add_special_tokens=True, padding=\"longest\")\n",
    "        input_ids = torch.tensor(ids['input_ids']).to(device)\n",
    "        attention_mask = torch.tensor(ids['attention_mask']).to(device)\n",
    "        embedding_repr = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        emb = embedding_repr.last_hidden_state[:,:window_size].detach().unsqueeze(1).to(device,dtype=torch.float32) # shape (batch x window_size x 1024)\n",
    "        outputs = mymodel(emb)\n",
    "        outputs = torch.nn.Softmax(dim=1)(outputs)\n",
    "        \n",
    "        mycolors = [\"#91F876\",\"#F64A4A\",\"#81FBFB\",\"#FFA07A\",\"#008000\",\"#C0C0C0\",\"#0280CE\",\"#800080\",\"#F0F01F\",\"#FF3EEE\",\"#000000\"]\n",
    "        #饼图\n",
    "        type_score = np.sum(np.array(outputs.cpu()), axis=0)\n",
    "        all_types = list(target_encode_dict.keys())\n",
    "        plotdata = pd.DataFrame({\"type\":all_types,\"type_score\":type_score})\n",
    "        fig2 = go.Figure(data=[go.Pie(labels=all_types, values=type_score, marker=dict(colors=mycolors), pull=[0]*(len(all_types)-1)+[0.2])])\n",
    "        fig2.update_layout(title=title, title_x=0.5)\n",
    "        \n",
    "        #折线图\n",
    "        values = np.array(outputs.view(-1).cpu())\n",
    "        types = all_types*len(outputs)\n",
    "        indices = [i+(window_size+1)/2 for i in list(range(0,len(seq)-window_size+1,step)) for _ in range(len(all_types))]\n",
    "        annotations = [\"[\"+str(int(indices[i]-(window_size-1)/2))+\", \"+str(int(indices[i]+(window_size-1)/2))+\"]: \"+str(types[i])+\"(\"+str(round(values[i],3))+\")\" for i in range(len(types))]\n",
    "        plotdata = pd.DataFrame({\"indices\":indices,\"types\":types,\"values\":values,\"annotations\":annotations})\n",
    "#         plt.figure(figsize=(15,8))\n",
    "#         custom_palette = sns.color_palette(mycolors)\n",
    "#         plot = sns.lineplot(data=plotdata,x=\"indices\",y=\"values\",hue=\"types\",palette=custom_palette)\n",
    "#         plot.set_title(title)\n",
    "#         plot.set_xlabel('pos')\n",
    "#         plot.set_ylabel('score')\n",
    "#         plt.axhline(y=0.5, color='red', linestyle='--', linewidth=1, label='Threshold')\n",
    "        grouped_data = plotdata.groupby('types')\n",
    "        sorted_types = [all_types[i] for i in sorted(range(len(all_types)), key=lambda i: type_score[i], reverse=True)]\n",
    "        fig1 = go.Figure()\n",
    "        fig1.add_shape(\n",
    "            type='line',\n",
    "            x0=0,  # 设置水平线的起点 x 坐标\n",
    "            y0=0.5,  # 设置水平线的 y 坐标\n",
    "            x1=len(seq),  # 设置水平线的终点 x 坐标\n",
    "            y1=0.5,  # 设置水平线的 y 坐标\n",
    "            line=dict(color='#F4D03F', width=2, dash='dash')  # 设置线条的颜色、宽度和样式为虚线\n",
    "        )\n",
    "        fig1.add_shape(\n",
    "            type='line',\n",
    "            x0=0,  # 设置水平线的起点 x 坐标\n",
    "            y0=0.8,  # 设置水平线的 y 坐标\n",
    "            x1=len(seq),  # 设置水平线的终点 x 坐标\n",
    "            y1=0.8,  # 设置水平线的 y 坐标\n",
    "            line=dict(color='red', width=2, dash='dash')  # 设置线条的颜色、宽度和样式为虚线\n",
    "        )\n",
    "        for group in sorted_types:\n",
    "            data = grouped_data.get_group(group)\n",
    "            fig1.add_trace(go.Scatter(x=data['indices'], y=data['values'], mode='lines+markers',line=dict(color=mycolors[all_types.index(group)]), name=group, text=data['annotations'], textposition='top center', hoverinfo='text'))\n",
    "        fig1.update_layout(title=title, title_x=0.5, xaxis_title='pos', yaxis_title='score', xaxis=dict(range=[0, len(seq)]), yaxis=dict(range=[0-0.05, 1+0.05]))\n",
    "        \n",
    "        #柱形图\n",
    "        \n",
    "        \n",
    "        #预测结果统计\n",
    "        max_indices = torch.argmax(outputs, dim=1)\n",
    "        preds = [all_types[i] for i in np.array(max_indices.cpu())]\n",
    "        counter = Counter(preds)\n",
    "        for element, count in counter.most_common():\n",
    "            print(f\"{element}: {count}\")\n",
    "        \n",
    "        fig1.show()\n",
    "        fig2.show()\n",
    "        return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f59ad5dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_seq(my_model, \"MMLPPRLQEHLATFLPAIRVGIDFGESAGGIAVVQGNQILHAETYIDFHNSDLGQRRQLRRGRRTRRAKKMRLARLRSWVLRQKLPDGTRLPDPYVVMRYPKFHVQPGVFKTKTPGRDSATVPSWIDLAKQGKVDASGFVRALTLIFQKRGFKWDAIELAKMTDEKMKDFLQTARVPSDNLASDIREEIQRRRQDSDSSGRGKKKVSPDELLALLEQARERQPQPRVAEHRSVKEADLRSAVEGFGNSINLTKATIQRWQRELSGLLNKVLRPARFENRLRTGCAWCGKPTPRKSKVREVAYEAAVRNLRVREGRSIRPLRPEEFAMFTQWWRLRGQAGESQQGGSEQKRSRKDRSQAIPKLKGIQSYLKKLGAQEQMARQIFDLLWNEKPQGRASLCQQHLSEAAQGRTMKDVVGEWHKVKVRKAPNPCREQHDTRVLHRLEQILFRPGKNGPDAWRYGPVQFITLEVPKPQTEQARRGEQKLRKPESFMERLRKETDGVCMYCDSSPPRPAEDKDHIFPQSRGGPDVWDNLVPVCRSCNMEKGNRTPFEWIGADGERWRRFTERVEGLAARGVRIEREDGKEETVRISERKRALLISQDTEYPDNPTSLAHVGARPRQFVVALRKLFEDRGVTAPSVNFESGVPFVQRIDGRTTFQLRKSWLKKADGSDNFPTKNEWDLLNHAQDAALIAACPPHTWRDLIFTHSAERPVWDGSWKQIPGLAIPALAPDWAEYLERRTWPLVKVLGRYPVSWKRKFADLTFSQNPDSVDDKRLVQYLLIADMPHSGKGPNDKRHPAETEIVNPALDKKFRAVATALGLKKKQTIPEKSLQEEFPGIRHVKVRKQRGGRLVRVKPKDGPPRKVEIKGASEAAVFWVANDDPLRDLRISVRWPVILGAMNVPRYEPSIPADARILATWSRYQLVRLGPEVTQKVGFYRVKEFDDSSVTVLPENAVPDAVAKRLNLKRQETEQETPEGSSPSQEIKLGKTLLMRYFQSLKGGKHHDPGTGS\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "824ebb2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cas9d_fa1 = read_fasta(project_path + \"/data/cas9d/\"+\"CN116096877A.FASTA\")\n",
    "cas9d_fa2 = read_fasta(project_path + \"/data/cas9d/\"+\"WO2021202559A1.FASTA\")\n",
    "cas9d_fa3 = read_fasta(project_path + \"/data/cas9d/\"+\"WO2023081855A1.FASTA\")\n",
    "cas9d_fa4 = read_fasta(project_path + \"/data/cas9d/\"+\"WO2023097262A1.FASTA\")\n",
    "cas9d_fa5 = read_fasta(project_path + \"/data/cas9d/\"+\"WO2023097282A1.FASTA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41748801",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in ['SEQ ID NO. 1294 in WO2023097282A1']:\n",
    "    predict_seq(my_model, cas9d_fa5[i],title=i,step=4)\n",
    "    print(\"--------------------------------------------------------------------------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97789bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in list(cas9d_fa2.keys()):\n",
    "    predict_seq(my_model, cas9d_fa2[i],title=i)\n",
    "    print(\"--------------------------------------------------------------------------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c973b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in list(cas9d_fa3.keys()):\n",
    "    predict_seq(my_model, cas9d_fa3[i],title=i,step=4)\n",
    "    print(\"--------------------------------------------------------------------------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87df7f0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in list(cas9d_fa4.keys()):\n",
    "    predict_seq(my_model, cas9d_fa4[i],title=i,step=4)\n",
    "    print(\"--------------------------------------------------------------------------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc154950",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in ['SEQ ID NO. 978 in WO2023097282A1']:\n",
    "    predict_seq(my_model, cas9d_fa5[i],title=i,step=4)\n",
    "    print(\"--------------------------------------------------------------------------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86593978",
   "metadata": {},
   "outputs": [],
   "source": [
    "test=read_fasta('/home/fengchr/staff/test_12_6/test.fa')\n",
    "for i in list(test.keys()):\n",
    "    predict_seq(my_model, test[i],title=i,step=4)\n",
    "    print(\"--------------------------------------------------------------------------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5099f104",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_seq(my_model, \"MSNDLNEHIDLPVISLQKTLEKLFGDEQFERTQHINFVVKLLSSQQADNFLGGLNLDYFNVDVEFQSNLPKPSLISFSKKVKISNLPITSYINSVAQLSASQTHAQHWNILVLKAAIYLIALPELKPELFKQAHTEHFNTVKRLFQRFRTANKNLDTEKKYQNTKEYQRLWSTYLQDPTQSLERFIQHLITLDTAELPEFDRNLLNDIRITFNYVLKNKAKIARASIDTQLEHQFLDEEQFIEESIEIKKGASPKALSIETLIDEPLHRQIVVNPTQVTPLAAHSETSQNYILPLVAKHIQRKEHLLTSSSFFPNPSSMNHLLKRLHVDYSEHQNKSALILMLAFLTGNSVNEWLYIQKSKRAKKLNNRQKLIYKNDQFFLNSHFNVFENRNFEYSDNLLNQTIYLDIPIPNLFIEDLRKMESVSFNEIQQYLRRLRQELFIPKLSVVKVSSLLHHTILSKTGNKQLADLMTGIDANQSSSVSYCHQNIPRLHAQYVDILKSLCADVASTYESCVPSLPDSIIHFGSRKAPKPQVITEIFAVLKFNIFSQAEDDLIAIYNHYNIWMWHILLLFTAARPVAEFPGFLKNFNLKRQILMVSDKEVGGRNGFGRLIPLCSFLVEEIKKFLKFLEYFSIQIAMNYPLLNDVIQQIETSKLPLLGIIQNNKWTPLRPSTVKDLYPELGLAHENWHRHTARAFLTHKFSEPEILALFGHELMQQEAAHPFSSLSLSQFSKIADVLEQMKTYFKITGVEAHVITQ\",title=\"YTGE-72\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82b47b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_seq(my_model, \"MSNDLNEHFDLPMISIKRTIEKLFGDEQFERAQHINFVIELLSSQQTDNCLDGLNLDCFDIDVEFQSNLPKPSVISFNKKVKISDLPITSYVNSISQLSESQTHAKNWNILVLKAAIYLIALPELKPDLFKQAHAEHFNTVKRLFQRFRTANKNLDTEKKYHNTEEYKRLWNVYLKDLTLSLEQFIQHLITLDTDELPEFDRNLLNDIRITFNYILKNKAKIARASIDTQLQHQFLDEEQFIEESIEIKKGAESKALNIETLIDEPINRQIVVNPTDVTPLAAHSETSQSYVLPLVAKHIQRKEHLLTSSSFFPNPSSVNHLLKRLHVDYSEHQNKSALILMLAFLTGNSVNEWLYIQSKRAKNLNNRQKLIHKNDQFFLNSKFNVFENRDFEYSTSLLNQTIYLDIPIPNLFIEDLRKMDSVSFDDIQQYLRKLRQELLIPKLSVIKVSSLLHHTVLAKTGNKQLADLITGIDANQSSSISYCHQNIPRLHAQYVDILKSLCADIASTYESCVPSPPDSIIHFGSRKAPKPQIITEIFAVLKFNIFSQAEDDLIAIYNHYNIWMWHILLLFTAARPVAEFPGFLKNFNLKRQILMVSDKEAGGRNGFGRLIPLCSFLVEEIKKFLKFLEYFSTQIMMSHPALSDAIQQIEASKLPFLGIIQNDEWKPLSHSTVKNFHPELGLAHENWHRHTARAFLTHKFSEPEILALFGHELMQQEAAHPFSSLSLSQFSKIADVLEQMKTYFKITGVEAHVITQ\",title=\"SRR6231193|NODE_1928_length_10001_cov_10.189624_2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6530b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_seq(my_model, \"MSIPAQLSAAVQTFLPTLRLGLDLGERAVGIAVVRGNEVLHAETVIDFHEATLKERRRLRRGRRTRRAKKSRIARLRSWILRQIVNGKRLPDPYILMRQKRFQCQPGEYRQKVQLAKSALPSWVEAVKQGRETSDEAFVIALTHLFQKRGYRWGGSDVQAMDDNTLADELRKIRLTPAVAEQVRREVERRKNDPNAPKGFTGKINGIEQLIEQALNRRRQPRVAEHRSIVEDEVRAVVTSFGRHHGIAEDTMTRWRAELVCLLNKPVRAARFENRALTGCTWCGAHTPKKSRPEVQELAYWAAVANVRVAAGRQPRPLTQSERAQFVEWWNADAQRRPTQPAIKRYLTSIGAQEEMARQFADLLNRRNLNGRTNLCLAHLREQAEGAFFCPQHQGVCRSAPNGQHRAVESARSRESSASRVWNPARAWHDRRVVARIERMLFMRDGTPRYGGIPSLITIEVPKPDTAHRYECPHCHEALAVNLRVRYRITKLELKPTKVRQNEAAFTCPQCRKPFEINGKRKIGTPNGLKPINVKLGLTHAVVWWAGGGKKARHVADTNGQCIYCGTNVDVGSVKLDHIFPQSMAGPGIYMNMVAACERCNNEKYNRTPWQWKGHDQAWWQAFEARLDRLFLPMRKREMLLSREASYPENPTALARVGGRAREFMRELQVMFARHAIPSERIVTGYRHDADIVMQMIEGWMTDRLRRSWMSGVDGRENFLPKDRADLRNHAQDAVLVAACPPHTWRERIFCYGPDRDMALPDLAPNWRNYESGMRDRHPLVVPLGRYRIRWRKQFLDQTFWKQPLGRKPVVYRQLAELKKSDASSIKDERIRCAFLSVCQAYNIGSEKTLTEDAQADLQNRLVSLGMVTPVRRVQCFSQKGGLPISVRPHDGPVRITQVKPTSDGVVLWLPAGVRLETARTRDLKISVIRPKPVVGWPSPDVPGQAVSELDPPVPPEAQRIATWYRYQCVRFSPHDGWYRLKEFSEKKLTVMPAIRLPKKLRNDAGGHDGEETGNDEREFGKEALLAAVRANAMATFCDPFD\",title=\"Cas9c2|MG33-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7607c1f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_seq(my_model, \"HAETYTDYHATTLEERRKMRRGRRTRHAKKLRLARLRSWLLRQTLPDPYDLMRRKDFQHPPLQLPQHLPVHRQESRTTSPWCHAVIKGHLNDPSAFVLALTHIFQKRGYKYDARDLSSLSPSELEEFLNSCCLLEQAGSLKDSLKGLVERVESNKLRNAYEKALTREPEPRKALPRQLKEDELKQLVKAFGSAQGLSPKQIVTWEKQLVGLLNKTIREPRFENRVIAGCSWCGKNTPRKSRKGVRELEFKAAVRNIRKDRVLPLDEQEALSFLHLWNDNAFRNKGLKARKQQFDKLLNSLRAQMDMASQLAELCGNDKGRGRANLCVDHLSLAADGAFKCNRHPGWLCKLGGAHEGHTQVEFVGGTGLTERLARNPCRETHEERVLRRLEEVLFDKSGNPRWGIPSLISIEFPKPGTAQTYDCPSCKEKLAIDLKVNRKIRKLSLGNAKRSDPQTSFACPFCNTGLFIKGTVKKPIGDRWEDRPVYLTHDEVYLRKAKGGMKEKKRAEYLRETNSTCVYCGQKIEDRLTMEPDHIFPRARGGPDVDSNLVASCHDCNHPNTGKGDRTPYEWIQRDGASPGGNDWSAFQKRVKSLPLPQRKRDVLLSDKEYYPDNPTALARATARKRAFIARIAKMLTDHGVPVDQIALNYETDKQVVIQAVDGWTTSRLRLSWRFHENGKPNFPQKKDWDLRNHAQDAALIAASPPHTWREAIFVETRPVDDPNKPIPGLAPRSLAPDWKGYLETIKDQKPLVSVLGRYDASWKRGFLDSTFWSFRSRNGHPTQRKQIDKVTAKQGDRIVDPKIKDAFRTLCESYGLVDRAGGFKDKPLPPEALEELRKQFPGIRRVRIVTQPGGKPILIQPQVGPPRQTQAKPGSEGIVLWLRLDTTKKRPREQTSEQFGLSLIRPAPLESFSVPRFEPPIPDDATAQLHLYRHDFIYLGENGIHPEGWYRLKEFSDDSVIALPEEAIPAELRKRMGLEQPGRKGSPSAAPAAPQERRLGKEELKGLLRSFRQRKLRIVKGGQ\",title=\"Cas9c2|MG33-9\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "650341f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_seq(my_model, \"MERELVLGIDYGGKYTGLAVVDRRHNQVLYANRLKMRDDVAGILKDRRKQRGIRRTAQTKKKRLRELKNYLKSIGYNESTATFETVYSLAHKRGYDYADMPEEKTSEEIEAMDVEERKQWEKEKQEWEETKRNSRHRKEVVKDVHKAMIEGRATEEQIKRVERIFNKQYRPKRFNNRILTKCKVEDCGVNTPLRKNVRDLLIENIVRFFPIEQSEKDNLKDAVLDKNRREEVKSFFRKHKTDEHIRKQVYDIADNKLSGRTVFCKEHILEHTEHSKEERKVFRLAPSLKTKIENVLAVIKDEILPKFTVNKVVMESNNFDIAAKTQGKKRLAKEEYGKGPREGKETRKEALLRETDGRCIYCGKSIDISNAHDDHIFPRKAGGLNIFANLVACCAVCNENKKGRTPLESGISPKPEIIAFMKNDLKKKILEDARNINTVDFNKYMSHASIGWRYMRDRLRESAGNKKLPIERQSGIYTAYFRRWWGFKKERGNTLHHALDAVILASRKGYSDDGLVDMTLKPKYNKGGEFDPEKHLPEPIEFKMDKGSRGSALHDRNPLSYKKGIITRRFMVTEIECGKEDDVISETYREKLKEAFKRFDTKKGKCLTDKEAKEAGFCIKKNELVMSLKCSIKGTGPGQMIRINNNVFKTNVHNVGVDVYLDEKGKKKAYERKNPRLSKHFIEPPPQPNGRVSFTLKRRDMVTVEGEDAIYRIKKLGTSPTIEAVVGSDGKTRTVSATKLTKANSAE\",title=\"Cas9d|MG34-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d4476bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_seq(my_model, \"MDMVYVLNKDGKPLMATTRGGRVRYLLKEKKARVVSSTPFTIQLNYDTPDITQDLILGIDPGRTNIGVAVVKEDGQCVFSAHLETRNKEVPLLMKKRAAFRRQHRTQDRRRKRQRRAIAAGTTVESNTIERLLPGYEKPIVCHHIRNKEARFNNRSRPAGWLTPTANHLLQTHINLIAKIAKVLPITKVVVELNRFAFMAMDNPNIRRWEYQQGSLYGLGSVEDAVYAQQDGHCLFCKKPIDHYHHVVPRHKGGSETLANRCGLCEKHHALVHKDKAWAEKLVTRKGGMNKKYHALSVLNQIIPFLMEYLGEETPYDVYATDGKSTKGFRIAKNVPKEHYTDAYCIACSILDADTKVSAPAEPFKLKQFRRHDRQSCIRQMVDRKYLLDGKVVATNRHKAIEQKSDSLEEFREAYGDAAVSQLTVRPHLPQYKDMTRIMPGAVMAFNGSVGVMQSSIVGSFYKSTKGHKATPRRCVLLAQNAGMVFNPA\",title=\"HEARO|MG35-287\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e93eef0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from PIL import Image\n",
    "import io\n",
    "from IPython.display import display\n",
    "import base64\n",
    "seq='MERELVLGIDYGGKYTGLAVVDRRHNQVLYANRLKMRDDVAGILKDRRKQRGIRRTAQTKKKRLRELKNYLKSIGYNESTATFETVYSLAHKRGYDYADMPEEKTSEEIEAMDVEERKQWEKEKQEWEETKRNSRHRKEVVKDVHKAMIEGRATEEQIKRVERIFNKQYRPKRFNNRILTKCKVEDCGVNTPLRKNVRDLLIENIVRFFPIEQSEKDNLKDAVLDKNRREEVKSFFRKHKTDEHIRKQVYDIADNKLSGRTVFCKEHILEHTEHSKEERKVFRLAPSLKTKIENVLAVIKDEILPKFTVNKVVMESNNFDIAAKTQGKKRLAKEEYGKGPREGKETRKEALLRETDGRCIYCGKSIDISNAHDDHIFPRKAGGLNIFANLVACCAVCNENKKGRTPLESGISPKPEIIAFMKNDLKKKILEDARNINTVDFNKYMSHASIGWRYMRDRLRESAGNKKLPIERQSGIYTAYFRRWWGFKKERGNTLHHALDAVILASRKGYSDDGLVDMTLKPKYNKGGEFDPEKHLPEPIEFKMDKGSRGSALHDRNPLSYKKGIITRRFMVTEIECGKEDDVISETYREKLKEAFKRFDTKKGKCLTDKEAKEAGFCIKKNELVMSLKCSIKGTGPGQMIRINNNVFKTNVHNVGVDVYLDEKGKKKAYERKNPRLSKHFIEPPPQPNGRVSFTLKRRDMVTVEGEDAIYRIKKLGTSPTIEAVVGSDGKTRTVSATKLTKANSAE'\n",
    "title='Cas9d|MG34-1'\n",
    "step=10\n",
    "response = requests.get('http://127.0.0.1:8040/predict/?seq='+seq+'&title='+title+'&step='+str(step))\n",
    "print(response.status_code)\n",
    "print(type(response))\n",
    "response=response.json()\n",
    "plot = response[\"img\"]\n",
    "stats = response[\"statistics\"]\n",
    "\n",
    "print(stats)\n",
    "\n",
    "img_io = io.BytesIO(base64.b64decode(plot))\n",
    "image = Image.open(img_io)\n",
    "display(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98de3690",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from PIL import Image\n",
    "import io\n",
    "from IPython.display import display_html\n",
    "seq='MERELVLGIDYGGKYTGLAVVDRRHNQVLYANRLKMRDDVAGILKDRRKQRGIRRTAQTKKKRLRELKNYLKSIGYNESTATFETVYSLAHKRGYDYADMPEEKTSEEIEAMDVEERKQWEKEKQEWEETKRNSRHRKEVVKDVHKAMIEGRATEEQIKRVERIFNKQYRPKRFNNRILTKCKVEDCGVNTPLRKNVRDLLIENIVRFFPIEQSEKDNLKDAVLDKNRREEVKSFFRKHKTDEHIRKQVYDIADNKLSGRTVFCKEHILEHTEHSKEERKVFRLAPSLKTKIENVLAVIKDEILPKFTVNKVVMESNNFDIAAKTQGKKRLAKEEYGKGPREGKETRKEALLRETDGRCIYCGKSIDISNAHDDHIFPRKAGGLNIFANLVACCAVCNENKKGRTPLESGISPKPEIIAFMKNDLKKKILEDARNINTVDFNKYMSHASIGWRYMRDRLRESAGNKKLPIERQSGIYTAYFRRWWGFKKERGNTLHHALDAVILASRKGYSDDGLVDMTLKPKYNKGGEFDPEKHLPEPIEFKMDKGSRGSALHDRNPLSYKKGIITRRFMVTEIECGKEDDVISETYREKLKEAFKRFDTKKGKCLTDKEAKEAGFCIKKNELVMSLKCSIKGTGPGQMIRINNNVFKTNVHNVGVDVYLDEKGKKKAYERKNPRLSKHFIEPPPQPNGRVSFTLKRRDMVTVEGEDAIYRIKKLGTSPTIEAVVGSDGKTRTVSATKLTKANSAE'\n",
    "title='Cas9d|MG34-1'\n",
    "step=8\n",
    "response = requests.get('http://127.0.0.1:8040/predict/?seq='+seq+'&title='+title+'&step='+str(step))\n",
    "print(response.status_code)\n",
    "print(type(response))\n",
    "response=response.json()\n",
    "fig1_html = response[\"fig1_html\"]\n",
    "fig2_html = response[\"fig2_html\"]\n",
    "stats = response[\"statistics\"]\n",
    "\n",
    "print(stats)\n",
    "display_html(fig1_html, raw=True)\n",
    "display_html(fig2_html, raw=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76d60162",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from PIL import Image\n",
    "import io\n",
    "from IPython.display import display_html\n",
    "seq='MERELVLGIDYGGKYTGLAVVDRRHNQVLYANRLKMRDDVAGILKDRRKQRGIRRTAQTKKKRLRELKNYLKSIGYNESTATFETVYSLAHKRGYDYADMPEEKTSEEIEAMDVEERKQWEKEKQEWEETKRNSRHRKEVVKDVHKAMIEGRATEEQIKRVERIFNKQYRPKRFNNRILTKCKVEDCGVNTPLRKNVRDLLIENIVRFFPIEQSEKDNLKDAVLDKNRREEVKSFFRKHKTDEHIRKQVYDIADNKLSGRTVFCKEHILEHTEHSKEERKVFRLAPSLKTKIENVLAVIKDEILPKFTVNKVVMESNNFDIAAKTQGKKRLAKEEYGKGPREGKETRKEALLRETDGRCIYCGKSIDISNAHDDHIFPRKAGGLNIFANLVACCAVCNENKKGRTPLESGISPKPEIIAFMKNDLKKKILEDARNINTVDFNKYMSHASIGWRYMRDRLRESAGNKKLPIERQSGIYTAYFRRWWGFKKERGNTLHHALDAVILASRKGYSDDGLVDMTLKPKYNKGGEFDPEKHLPEPIEFKMDKGSRGSALHDRNPLSYKKGIITRRFMVTEIECGKEDDVISETYREKLKEAFKRFDTKKGKCLTDKEAKEAGFCIKKNELVMSLKCSIKGTGPGQMIRINNNVFKTNVHNVGVDVYLDEKGKKKAYERKNPRLSKHFIEPPPQPNGRVSFTLKRRDMVTVEGEDAIYRIKKLGTSPTIEAVVGSDGKTRTVSATKLTKANSAE'\n",
    "title='Cas9d|MG34-1'\n",
    "step=8\n",
    "response = requests.get('http://127.0.0.1:8040/predict/?seq='+seq+'&title='+title+'&step='+str(step)+'&return_type=raw')\n",
    "print(response.status_code)\n",
    "print(type(response))\n",
    "response=response.json()\n",
    "print(type(response))\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b83e211f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
